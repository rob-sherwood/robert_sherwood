{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transient Water Release and Imbibitions Method Data (TRIM) Processing Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase I: Experimental setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Specify which cell you will be using; spell in all lower case letters, (e.g., small or large): small\n",
      "Insert the mass of dry solids in gr. (e.g., 170.00): 170\n",
      "Insert the specific gravity of solids (e.g., 2.70): 2.7\n",
      "Insert the target dry density of the sample in gr./cm^3 (e.g., 1.695): 1.695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compact the 170.0 gr. of dry meaterial to a hieght of 3.35 [cm] (i.e. 3.25 cm from the top of the acrylic housing).\n",
      "\n",
      "After compaction, take three depth measurements between the top of the acrylic housing and the sample surface; measure in cm. Those measurements will be used to calculate the actual sample dry density gr./cm^3, porosity, and the mass of water required to saturate the sample gr. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "When you have your depth measurements ready, press Enter: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Insert the three sample height measurements in cm.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Actual depth #1 (e.g., 3.26): 3.26\n",
      "Actual depth #2 (e.g., 3.24): 3.24\n",
      "Actual depth #3 (e.g., 3.25): 3.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following is a summary of experimental setup information. It was transfered to the Sample_Design.txt file. \n",
      " \n",
      " Summary of Experimental Setup \n",
      " TRIM cell info... \n",
      " \t Cell type =  small \n",
      " \t Diameter = 6.175 [cm] \n",
      " \t Height = 6.597 [cm] \n",
      " Soil sample info... \n",
      " \t Total Dry Mass (Ms) = 170.0 [gr.] \n",
      " \t Specific Gravity (Gs) = 2.7 [gr./gr.] \n",
      " \t Height (H) = 3.35 [cm] \n",
      " \t Dry Density (rho_dry) = 1.7 [gr./cm^3] \n",
      " \t Porosity (n) = 0.372 \n",
      " \t Mass of H2O to Saturate (Mw) = 37.09 [gr.]\n"
     ]
    }
   ],
   "source": [
    "# Allows the user to select which TRIM cell will be used.\n",
    "Cell = input(\"Specify which cell you will be using; spell in all lower case letters, (e.g., small or large):\")\n",
    "\n",
    "# Sellects the approprate sell dimentions based on the sell name: small or large.\n",
    "if Cell == 'small':\n",
    "    D_cell = 6.175   # [cm]\n",
    "    H_cell = 6.597   # [cm]\n",
    "else:\n",
    "    D_cell = 25.50   # [cm]\n",
    "    H_cell = 17.80   # [cm]\n",
    "\n",
    "# Calcualtes the cross section area of the flow cell (A_cell in cm^2).\n",
    "A_cell = np.pi * D_cell **2 /4   # [cm^2]    \n",
    "\n",
    "#........................................................................................................................\n",
    "\n",
    "# User Input Sample Information: \n",
    "## mass of dry solids (Ms in gr.), \n",
    "## specific gravity of solids (Gs), and \n",
    "## target dry density of sample (rho_d in gr./cm^3). \n",
    "Ms = float(input(\"Insert the mass of dry solids in gr. (e.g., 170.00):\"))\n",
    "Gs = float(input(\"Insert the specific gravity of solids (e.g., 2.70):\"))\n",
    "rho_dry = float(input(\"Insert the target dry density of the sample in gr./cm^3 (e.g., 1.695):\"))\n",
    "\n",
    "# Calcualting the desing height (H in cm) required to meet target dry density.\n",
    "H = Ms / rho_dry / A_cell   # [cm]\n",
    "H_from_top = H_cell - H     # [cm]\n",
    "\n",
    "# Brief report of sample design information; gives the user an oportunity to construct the sampel before moving to the next step.\n",
    "print(\"\\nCompact the\", Ms, \"gr. of dry meaterial to a hieght of\", round(H,2), \n",
    "      \"[cm] (i.e.\", round(H_from_top,2), \"cm from the top of the acrylic housing).\")\n",
    "print(\"\\nAfter compaction, take three depth measurements between the top of the acrylic housing and the sample surface; measure in cm. Those measurements will be used to\",\n",
    "      \"calculate the actual sample dry density gr./cm^3, porosity, and the mass of water required to saturate the sample gr. \\n\")\n",
    "Next_step = input(\"When you have your depth measurements ready, press Enter:\")   # Gives the user control over progression to the next step.\n",
    "\n",
    "# User input: three measurements of the depth to the sample surface (Dpth# in cm).\n",
    "print(\"\\nInsert the three sample height measurements in cm.\")\n",
    "Dpth1 = float(input(\"Actual depth #1 (e.g., 3.26):\"))   # [cm]\n",
    "Dpth2 = float(input(\"Actual depth #2 (e.g., 3.24):\"))   # [cm]\n",
    "Dpth3 = float(input(\"Actual depth #3 (e.g., 3.25):\"))   # [cm]\n",
    "\n",
    "# Calcualtes the average sample height in cm.\n",
    "H_avg = H_cell - np.average([Dpth1, Dpth2, Dpth3])   # [cm]\n",
    "\n",
    "# Defining the density of water at 20C.\n",
    "rho_w = 0.9982   # [gr./cm^3]\n",
    "\n",
    "# Calculates the porosity of the sample (n) and the mass of water required to saturate the sample (Mw in gr.) based on the average measured sample hieght.\n",
    "n = 1 - (Ms / (Gs * H_avg * A_cell))    # [no units]\n",
    "Mw = H_avg * A_cell * rho_w - Ms / Gs   # [gr.]\n",
    "\n",
    "#........................................................................................................................\n",
    "\n",
    "# Creating and reporting imortant sampe desing information to a .txt file for convienient storage.\n",
    "fh = open(\"Sample_Design.txt\", \"w\")\n",
    "fh.writelines([\"Summary of Experimental Setup \\n TRIM cell info... \\n \\t Cell type = \", Cell, \"\\n \\t Diameter = \", str(D_cell), \" [cm] \\n \\t Height = \", str(H_cell), \" [cm]\",\n",
    "               \"\\n Soil sample info... \\n \\t Total Dry Mass (Ms) = \", str(Ms), \" [gr.] \\n \\t Specific Gravity (Gs) = \", str(round(Gs,2)), \" [gr./gr.] \\n \\t Height (H) = \", \n",
    "               str(round(H_avg,2)), \" [cm] \\n \\t Dry Density (rho) = \", str(round(rho_dry,2)), \" [gr./cm^3] \\n \\t Porosity (n) = \", str(round(n,3)), \n",
    "               \"\\n \\t Mass of H2O to Saturate (Mw) = \", str(round(Mw,2)), \" [gr.]\"])\n",
    "fh.close()\n",
    "\n",
    "# Giving an in-Python display of what was exported to the .txt file.\n",
    "print(\"\\nThe following is a summary of experimental setup information. It was transfered to the Sample_Design.txt file. \\n \\n Summary of Experimental Setup\", \n",
    "      \"\\n TRIM cell info... \\n \\t Cell type = \", Cell, \"\\n \\t Diameter =\", D_cell, \"[cm] \\n \\t Height =\", H_cell, \"[cm] \\n Soil sample info... \\n \\t\", \n",
    "      \"Total Dry Mass (Ms) =\", Ms, \"[gr.] \\n \\t Specific Gravity (Gs) =\", round(Gs,2), \"[gr./gr.] \\n \\t Height (H) =\", round(H_avg,2), \n",
    "      \"[cm] \\n \\t Dry Density (rho_dry) =\", round(rho_dry,2), \"[gr./cm^3] \\n \\t Porosity (n) =\", round(n,3), \"\\n \\t Mass of H2O to Saturate (Mw) =\", round(Mw,2), \"[gr.]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase II: Processing raw TRIM data; preparation of inputs for Hydrus ID model use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining functions needed of data processing.\n",
    "\n",
    "def sample_pts2(points, max_time_step, max_points):\n",
    "\n",
    "    \"\"\"This function samples points form the outflow data. \n",
    "    It samples less points where the plot of the data is flat and more points where the \n",
    "    plot of the data is curved. Points are selected based on a time step and a mass step.\"\"\"\n",
    "    \n",
    "    # Prealocating list to store data selected data points in.\n",
    "    chosen_pts = []\n",
    "\n",
    "    # Specifying the starting place for point to point comparison (point 'a' to point 'b').\n",
    "    # Also adding the first point (point a) to the prealocated list 'chosen'.\n",
    "    a = np.min(points)\n",
    "    b = a + 1\n",
    "    chosen_pts.append(a)\n",
    "    \n",
    "    # Creates short-hand variables for a shorter code. The lond had names are used in the definition line to provide more clear explanation.\n",
    "    mx_ts = max_time_step\n",
    "    mx_ps = max_points\n",
    "\n",
    "    # Finds the max and minimum in the list of points.\n",
    "    top = np.max(points)\n",
    "    bottom = np.min(points)\n",
    "\n",
    "    # For loop to exicute point to point comparison while changing the step distances to accomodate for curviture of the plot and sampling rates of the data.\n",
    "    for count in range(len(points)):\n",
    "        if (df.Delta_sec[b] - df.Delta_sec[a]) <= mx_ts or (df['Mass (g)'][b] - df['Mass (g)'][a]) < (df['Mass (g)'][top] - df['Mass (g)'][bottom]) / mx_ps:\n",
    "            b = b + 1   # Increases the step by an incrament of 1 (one) to when the time step or mass step are smaller than desired.\n",
    "        else:\n",
    "            #while (df['Mass (g)'][b] - df['Mass (g)'][a])/(df.Delta_sec[b] - df.Delta_sec[a])/3600 > 0.01 # [gr./hr]\n",
    "            chosen_pts.append(b)   # Collects the desired points.\n",
    "            a = b              # Resetting the first point of comparison to the previously found desired point.\n",
    "            b = b + 1          # Stepping forwar one point to initiate the process of selecting the next desired point.\n",
    "    \n",
    "    # Returning a dataframe of the selected points.\n",
    "    return(pd.DataFrame({'chosen_pts': chosen_pts}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please specify the path to csv file of raw TRIM data which you wish to process; note that the name you enter must contain .csv at the end (e.g., Valley_Sub_raw.csv): Valley_Sub_raw.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Unnamed: 3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Unnamed: 3'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-26be3b57835f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m## Giving a meaningful names to a column of data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Mass'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Unnamed: 3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Uair (kPa)'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Step'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Unnamed: 3'"
     ]
    }
   ],
   "source": [
    "### Reading raw evaporation data.\n",
    "fh_raw = input(\"Please specify the path to csv file of raw TRIM data which you wish to process; note that the name you enter must contain .csv at the end (e.g., Valley_Sub_raw.csv):\")\n",
    "df = pd.read_csv((str(fh_raw)), sep = '\\t')\n",
    "#df = pd.read_csv(\"AGRON 935\\Valley_Sub_raw.csv\", sep = \"\\t\")\n",
    "\n",
    "#........................................................................................................................\n",
    "\n",
    "# Defining the dataframe of interest to be used for calculaitng the evaporation rate.\n",
    "\n",
    "## Excludes the NAN's at the very end of the dataframe.\n",
    "start = 0\n",
    "end = len(df)-1    \n",
    "df = df[start:end]\n",
    "\n",
    "## Giving a meaningful names to a column of data.\n",
    "df['Mass'] = df['Unnamed: 3']\n",
    "df['Uair (kPa)'] = df['Step']\n",
    "df['Step'] = df['Time']\n",
    "df['Time'] = df['Unnamed: 1']\n",
    "df = df.drop(columns=['Unnamed: 1','Unnamed: 3','Unnamed: 5','Notes'])\n",
    "\n",
    "## Converting time from [[YYYY/MM/DD], [HH:MM AM/PM]] to [sec] for calculations and plotting.\n",
    "df['Datetime'] = pd.to_datetime(df.Date + \" \" + df.Time)                  # from [[MM/DD/YYYY], [HH:MM, AM/PM]] to [YYYY/MM/DD, HH:MM:SS].\n",
    "df['Time_diff']= df.Datetime - df.Datetime[start]                         # from [YYYY/MM/DD, HH:MM:SS] to [days, HH:MM:SS].\n",
    "df['Delta_sec']= df.Time_diff.dt.days * 86400 + df.Time_diff.dt.seconds   # from [days, HH:MM:SS] to [sec].\n",
    "\n",
    "#........................................................................................................................\n",
    "\n",
    "# Sort data based on step type: 'Before Test', 'small increment', and 'Large increment'.\n",
    "\n",
    "## Removing 'Before Test' data.\n",
    "idx = df.Step != \"Before Test\"      # Identifies the rows to keep: 'small' and 'Large increments' which are not 'Before Test'.\n",
    "df = df[idx]                        # Applies the index to the dataframe removing the 'Before Test' data.\n",
    "df = df.reset_index(0)              # Resets the index to zero.\n",
    "df = df.drop(columns = ['index'])   # Drops the old index column.\n",
    "\n",
    "## Preallocate lists to store appropriate index values.\n",
    "sm_inc_idx = []\n",
    "lg_inc_idx = []\n",
    "\n",
    "## Using a for loop to sort index values based on step: 'samll increment' and 'Large increment'.\n",
    "for index in range(len(df.Step)):    \n",
    "    if df.Step[index] == \"small increment\":\n",
    "        sm_inc_idx.append(index)\n",
    "    else:\n",
    "        lg_inc_idx.append(index)\n",
    "\n",
    "#........................................................................................................................\n",
    "\n",
    "# Calculating the rate of diffused air, and correcting the large increment data for diffused air.\n",
    "\n",
    "## User input Bubble Trap measurement, in mL.\n",
    "bub_trap = float(input(\"Input the amount of air measured in the bubble trap, in mL (e.g., 2.7):\"))   # [mL]\n",
    "\n",
    "## Calculate the mass of water released during the Large increment, in grams. \n",
    "#H2O_lg_inc = df.Mass[np.max(lg_inc_idx)] - df.Mass[np.min(lg_inc_idx)]   # [gr.]\n",
    "H2O_out = df.Mass[np.max(lg_inc_idx)]   # [gr.]\n",
    "\n",
    "## Calculate the rate of diffused air during the Large increment.\n",
    "rt_diff_air = bub_trap / H2O_out #lg_inc   # [ml H2O displaced / grams large increment H2O outflow] = [gr./gr.], when rho_H2O=1.0 gr/ml\n",
    "print(\"The rate of diffused air is:\", round(rt_diff_air,2), \"gr./gr.\")\n",
    "\n",
    "## Create an array of large increment mass values for element-wise corrections.\n",
    "lg_inc_array = np.array(df.Mass)\n",
    "\n",
    "## Prealocate a temporary list to store corrected mass values.\n",
    "Corrected_masses = []\n",
    "\n",
    "## Using a for loop for elementwise correction of the large increment; the for loop is indexed to apply the correction to the large increment data only.\n",
    "## Equation: Correct_Mass1[gr.] = Mass1[gr.] - (Mass1[gr.] - Mass0[gr.]) * Rate_diff_air[ml/gr.]\n",
    "for index in range(len(df.Mass)-1): #np.min(lg_inc_idx),np.max(lg_inc_idx)):\n",
    "    new_mass = lg_inc_array[index] - (lg_inc_array[index+1] - lg_inc_array[index]) * rt_diff_air\n",
    "    #new_mass = lg_inc_array[index] - (lg_inc_array[index] - lg_inc_array[index-1]) * rt_diff_air\n",
    "    Corrected_masses.append([new_mass])\n",
    "\n",
    "#........................................................................................................................\n",
    "\n",
    "# Replacing the old large increment masses with those corrected for diffused air.\n",
    "\n",
    "## Create a second dataframe of corrected large increment masses.\n",
    "df2 = pd.DataFrame(Corrected_masses)\n",
    "#df2['Mass'] = df2                                   # [gr.]\n",
    "df['Mass'] = df2                                   # [gr.]\n",
    "\n",
    "## Using a for loop to replace the old large increment masses in the \n",
    "## original dataframe with the new/corrected masses in the second dataframe.\n",
    "#for index in range(np.min(lg_inc_idx), np.max(lg_inc_idx)):\n",
    "#    index2 = index - np.min(lg_inc_idx)\n",
    "#    old_mass = df.Mass[index]                       # [gr.]\n",
    "#    new_mass = df2.Mass[index2]                     # [gr.]\n",
    "#    df.Mass = df.Mass.replace(old_mass, new_mass)   # [gr.]\n",
    "\n",
    "#........................................................................................................................   \n",
    "\n",
    "# Correcting all mass measurements for evaportion and for oversaturation.\n",
    "\n",
    "# Retrieving sample specifications from the sample design sheet: sample height (H_sample) [cm],\n",
    "# sample diameter (D_sample) [cm], and porosity (n).\n",
    "\n",
    "## Opening the text file.\n",
    "fh_SD = open(\"Sample_Design.txt\", \"r\")\n",
    "fh_SD = fh_SD.read()\n",
    "\n",
    "## Segragating the text into managable strings.\n",
    "fh_SD = re.sub(' \\t ', '', fh_SD)\n",
    "fh_SD = fh_SD.split('\\n')\n",
    "fh_SD = pd.DataFrame(fh_SD)\n",
    "\n",
    "##  Extracting the values of required_water [gr.].\n",
    "required_water = fh_SD[0][11]; required_water = required_water.split(' '); required_water = float(required_water[7])\n",
    "\n",
    "## User inputs the mass of water required to saturate the sample and the amount that was in the sample when the test was initiated.\n",
    "#required_water = float(input(\"Input the mass of water required to saturate the sampe, in gr.:\"))   # [gr.]\n",
    "imbibed_water = float(input(\"Input the mass of water imbibed into the sampe, in gr. (e.g., 37.00):\"))            # [gr.]\n",
    "print(\" \") # Making some space for readability of printed information.\n",
    "\n",
    "## Equaiton: Correct_Mass1[gr.] = Mass1[gr.] + Comulative_time[sec] * Evap_rate[gr./sec]\n",
    "evap_rate = 0.0927/86400                                      # [gr./sec], Evaporation rate is constant.\n",
    "excess_water = imbibed_water - required_water                 # [gr.]\n",
    "df.Mass = df.Mass + df.Delta_sec * evap_rate - excess_water   # [gr.]\n",
    "\n",
    "## Updataing the 'Mass (g)' column with the corrected 'Mass' values, and removing the rows with negative mass values.\n",
    "df['Mass (g)'] = df.Mass\n",
    "df = df.drop(columns = ['Mass'])\n",
    "idx = df['Mass (g)'] > 0                                     # Developing a boolian index to excluded negative mass values.\n",
    "df = df[idx]                                                 # selecting range of rows in the dataframe that have positive mass values.\n",
    "df = df.reset_index(0)                                       # Resetting the index to start with zero.\n",
    "df = df.drop(columns = ['index', 'Datetime', 'Time_diff'])   # Removing un-needed columns of transitional information.\n",
    "\n",
    "#........................................................................................................................\n",
    "\n",
    "# Redefine the 'small increment', and 'Large increment' indexes.\n",
    "\n",
    "## Preallocate lists to store appropriate index values.\n",
    "sm_inc_idx = []\n",
    "lg_inc_idx = []\n",
    "\n",
    "## Using a for loop to sort index values based on step: 'samll increment' and 'Large increment'.\n",
    "for index in range(len(df.Step)):    \n",
    "    if df.Step[index] == \"small increment\":\n",
    "        sm_inc_idx.append(index)\n",
    "    else:\n",
    "        lg_inc_idx.append(index)\n",
    "        \n",
    "#........................................................................................................................\n",
    "\n",
    "# Sampling data from the corrected TRIM data.\n",
    "\n",
    "## Specifying the step size for time and mass.\n",
    "mx_ts = 300   # Should not exceed the max sampling rate used to collect the TRIM experiment data, typically 300 seconds.\n",
    "mx_ps = 100   # Should not be less than the minimum number of points recommended for inverse modeling procedures: 100 points, (Wayllace and Lu 2012).\n",
    "\n",
    "## Exicuting the sampling function for the small and the large step incraments of the TRIM test individually, then combining the two dataframes into one.\n",
    "chosen_sm = sample_pts2(range(np.min(sm_inc_idx),np.max(sm_inc_idx)),mx_ts,mx_ps)\n",
    "chosen_lg = sample_pts2(range(np.min(lg_inc_idx),np.max(lg_inc_idx)),mx_ts,mx_ps)\n",
    "df3 = chosen_sm.append(chosen_lg)\n",
    "\n",
    "## Optimizing the step size to meet or slightly exceed the minium number of points for modeling. The minimum number of point required is 100.\n",
    "while len(df3) < 150:\n",
    "    \n",
    "    df3 = []   # Emptying the dataframe\n",
    "    \n",
    "    ## Adjusting the step sizes\n",
    "    mx_ts = mx_ts - 25\n",
    "    mx_ps = mx_ps + 25\n",
    "    \n",
    "    ## Re-exicuting the sampling fucntion with the adjusted step sizes and merging the two dataframes into one.\n",
    "    chosen_sm = sample_pts2(range(np.min(sm_inc_idx),np.max(sm_inc_idx)),mx_ts,mx_ps)\n",
    "    chosen_lg = sample_pts2(range(np.min(lg_inc_idx),np.max(lg_inc_idx)),mx_ts,mx_ps)\n",
    "    df3 = chosen_sm.append(chosen_lg)\n",
    "\n",
    "#........................................................................................................................ \n",
    "\n",
    "# Plotting the selected points to show the sampled data.\n",
    "plt.scatter(df.Delta_sec.reindex(df3.chosen_pts), df['Mass (g)'].reindex(df3.chosen_pts), alpha = 0.5, label=\"Sampled Points\", color = \"green\")\n",
    "plt.title(\"$Sampled\\ Outflow\\ Data$\", fontsize = 16)\n",
    "plt.ylabel(\"$Mass\\ H_2O\\ Out\\ (gr.)$\", fontsize = 14)\n",
    "plt.xlabel(\"$Time\\ (sec)$\", fontsize = 14)\n",
    "plt.legend(loc = 4) # Positions legend in the lower right corner.\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## Plot caption...\n",
    "print(\"Figure 1: plot of sampled outflow data; data are corrected for diffused air, evaporation, and saturation error.\")\n",
    "\n",
    "#........................................................................................................................ \n",
    "\n",
    "# Exporting the sampled points as .csv file: TRIM_input.csv.\n",
    "\n",
    "## Create a dataframe to store all the information that are to be exported.\n",
    "TRIM_input = pd.DataFrame()\n",
    "\n",
    "## Add all the appropriate data to that dataframe: data are selected using the sampled points as an index \n",
    "## so that the corresponding data for each selected point is collected.\n",
    "TRIM_input['Date'] = df.Date[df3.chosen_pts]                          # [MM/DD/YYYY]\n",
    "TRIM_input['Time'] = df.Time[df3.chosen_pts]                          # [HH:MM:SS AM/PM]\n",
    "TRIM_input['Step'] = df.Step[df3.chosen_pts]                          # [small increment or Large increment]\n",
    "TRIM_input['Mass (g)'] = df['Mass (g)'].reindex(df3.chosen_pts)       # [gr.]\n",
    "TRIM_input['Uair (kPa)'] = df['Uair (kPa)'].reindex(df3.chosen_pts)   # [kPa]\n",
    "\n",
    "## Sets the 'Date' column as the dataframe index.\n",
    "TRIM_input = TRIM_input.set_index('Date')\n",
    "\n",
    "## Create a csv file for the dataframe to be passed to and stored in.\n",
    "TRIM_input.to_csv(\"TRIM_input.csv\", sep = \"\\t\")\n",
    "\n",
    "## Notify the user that the data has been exported to the csv file.\n",
    "print(\"\\nThe sampled outflow data in Figure 1 were exported to the csv file: TRIM_input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Step</th>\n",
       "      <th>Mass (g)</th>\n",
       "      <th>Uair (kPa)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>9:19:52 AM</td>\n",
       "      <td>small increment</td>\n",
       "      <td>0.090032</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>9:22:02 AM</td>\n",
       "      <td>small increment</td>\n",
       "      <td>0.120172</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>9:24:12 AM</td>\n",
       "      <td>small increment</td>\n",
       "      <td>0.140311</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>9:26:23 AM</td>\n",
       "      <td>small increment</td>\n",
       "      <td>0.160452</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>9:28:33 AM</td>\n",
       "      <td>small increment</td>\n",
       "      <td>0.190591</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>7/25/2019</td>\n",
       "      <td>8:41:29 PM</td>\n",
       "      <td>Large increment</td>\n",
       "      <td>24.956611</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>7/25/2019</td>\n",
       "      <td>11:01:31 PM</td>\n",
       "      <td>Large increment</td>\n",
       "      <td>25.045626</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>7/26/2019</td>\n",
       "      <td>1:21:35 AM</td>\n",
       "      <td>Large increment</td>\n",
       "      <td>25.134643</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>7/26/2019</td>\n",
       "      <td>3:21:37 AM</td>\n",
       "      <td>Large increment</td>\n",
       "      <td>25.229144</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>7/26/2019</td>\n",
       "      <td>4:36:39 AM</td>\n",
       "      <td>Large increment</td>\n",
       "      <td>25.327200</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date         Time             Step   Mass (g)  Uair (kPa)\n",
       "0    7/24/2019   9:19:52 AM  small increment   0.090032         3.0\n",
       "1    7/24/2019   9:22:02 AM  small increment   0.120172         4.0\n",
       "2    7/24/2019   9:24:12 AM  small increment   0.140311         4.0\n",
       "3    7/24/2019   9:26:23 AM  small increment   0.160452         4.0\n",
       "4    7/24/2019   9:28:33 AM  small increment   0.190591         4.0\n",
       "..         ...          ...              ...        ...         ...\n",
       "153  7/25/2019   8:41:29 PM  Large increment  24.956611       290.0\n",
       "154  7/25/2019  11:01:31 PM  Large increment  25.045626       290.0\n",
       "155  7/26/2019   1:21:35 AM  Large increment  25.134643       290.0\n",
       "156  7/26/2019   3:21:37 AM  Large increment  25.229144       290.0\n",
       "157  7/26/2019   4:36:39 AM  Large increment  25.327200       290.0\n",
       "\n",
       "[158 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file to check for mistakes.\n",
    "pd.read_csv(\"TRIM_input.csv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TRIM_input.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase III: Plotting the objective function, SWCC, and HCF from Hydrus 1D output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5630d3178b8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m## Establishing the column titles using the existing titles printed by Hydrus 1D.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mdf_fit_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_fit_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_fit_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mdf_fit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_fit_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "# Openging the data Hydrus 1D output file (Fit.out) and formating the informations to make it \n",
    "# readable and sepparable.\n",
    "\n",
    "## Opening the .out file.\n",
    "fh = open(\"Valley_Sub_AGProj\\Fit.out\", \"r\")\n",
    "fh = fh.read()\n",
    "\n",
    "## Segragating the main text into idealized groups (strings) for easy access and minipulation.\n",
    "fh = re.split(\"\\n\\n\\n\", fh)\n",
    "\n",
    "#........................................................................................................................\n",
    "\n",
    "# Handling of estimated parameters - sum of squared error (SSQ) and van Genuchten fitting parameters: \n",
    "# residual water content (WCR), air entry (ALPHA)[1/cm], pore size distribution coefficient (N),\n",
    "# and saturated hydraulic conductiviyt (COND)[cm/s].\n",
    "\n",
    "## Accessing the estimated parameters fromt the main text file.\n",
    "fh_fit_params = fh[5]\n",
    "\n",
    "## Formatting strings to be converted into a DataFrame.\n",
    "fh_fit_params = re.split('\\n', fh_fit_params)\n",
    "\n",
    "for i in range(len(fh_fit_params)):        \n",
    "    fh_fit_params[i] = re.sub('SSQ', '  SSQ', fh_fit_params[i])\n",
    "    fh_fit_params[i] = re.sub('      ', ' ', fh_fit_params[i])\n",
    "    fh_fit_params[i] = re.sub('     ', ' ', fh_fit_params[i])\n",
    "    fh_fit_params[i] = re.sub('    ', '  ', fh_fit_params[i])\n",
    "    fh_fit_params[i] = re.sub('D+','E', fh_fit_params[i])\n",
    "    fh_fit_params[i] = re.sub('CONES ', 'K_sat', fh_fit_params[i])\n",
    "    fh_fit_params[i] = re.split('  ', fh_fit_params[i])\n",
    "        \n",
    "## Putting data into a DataFrame: df_fit_params.\n",
    "df_fit_params = pd.DataFrame(fh_fit_params)\n",
    "df_fit_params = df_fit_params[4:]\n",
    "\n",
    "## Establishing the column titles using the existing titles printed by Hydrus 1D.\n",
    "for i in range(6):\n",
    "    df_fit_params[df_fit_params[i][4]] = df_fit_params[i]\n",
    "    df_fit_params = df_fit_params.drop(columns = [i])\n",
    "\n",
    "## Dropping unneccessary rows and columns, and resetting the index to start from zero.\n",
    "df_fit_params = df_fit_params[1:]\n",
    "df_fit_params = df_fit_params.reset_index(0)\n",
    "df_fit_params = df_fit_params.drop(columns = ['index'])\n",
    "\n",
    "SSQ = (\"$SSQ$    =\" + df_fit_params.SSQ[len(df_fit_params.SSQ)-1])\n",
    "ALPHA = (\"$\\u03B1$  = \" + df_fit_params.ALPHA[len(df_fit_params.ALPHA)-1])   # \\u03B1 is unicode for alpha.\n",
    "K_SAT = (\"$K_s$ = \" + df_fit_params.K_sat[len(df_fit_params.K_sat)-1])\n",
    "\n",
    "## Converting all DataFrame info from type string to type float for plotting and potential calculations.\n",
    "for j in range(len(df_fit_params)):\n",
    "    df_fit_params['SSQ'][j] = float(df_fit_params['SSQ'][j])       # -           Sum of Squared Error\n",
    "    df_fit_params['WCR'][j] = float(df_fit_params['WCR'][j])       # [cm^3/cm^3] Residual Volumetric Water Content\n",
    "    df_fit_params['ALPHA'][j] = float(df_fit_params['ALPHA'][j])   # [1/cm]      Fitting Parameter: ~Inverse of Air Entry\n",
    "    df_fit_params['N'][j] = float(df_fit_params['N'][j])           # -           Fitting Parameter: ~Pore Size Distribution\n",
    "    df_fit_params['K_sat'][j] = float(df_fit_params['K_sat'][j])   # [cm/s]      Saturated Hydraulic Conductivity\n",
    "    \n",
    "WCR = (\"$\\u03B8_r$ = \" + str(df_fit_params.WCR[len(df_fit_params.WCR)-1]))   # \\u03B8 is unicode for theta.\n",
    "N = (\"$n$  = \" + str(df_fit_params.N[len(df_fit_params.N)-1]))\n",
    "\n",
    "#........................................................................................................................\n",
    "\n",
    "# Handling of Fit statistics: Regression coefficient (R^2) and root mean square error (RMSE).\n",
    "\n",
    "## Accessing the fit statistics fromt the main text file.\n",
    "fh_fit_stats = fh[8]\n",
    "\n",
    "## Formatting strings to be converted into a DataFrame.\n",
    "fh_fit_stats = re.sub(\"\\n\\n\", \"\\t\\t\", fh_fit_stats)\n",
    "fh_fit_stats = re.sub(\"\\n\", \"\\t\\t\", fh_fit_stats)\n",
    "fh_fit_stats = re.split(\"\\t\\t \", fh_fit_stats)\n",
    "R_2 = fh_fit_stats[2]\n",
    "RMSE = fh_fit_stats[5]\n",
    "R_2 = re.split(\"=\", R_2)\n",
    "R_2_value = \"$R^2$      = \" + (R_2[1])\n",
    "RMSE = re.split(\":  \", RMSE)\n",
    "RMSE_value = \"$RMSE$ = \" + (RMSE[1])\n",
    "\n",
    "#........................................................................................................................\n",
    "\n",
    "# Handeling of observed (Obs) and calculated (Fitted) transient outflow data, from TRIM experiment and\n",
    "# numerical solution of Richards' equation, respectively.\n",
    "\n",
    "## Accessing the observed and calculated outflow data fromt the main text file.\n",
    "fh_fit = fh[10]\n",
    "\n",
    "## Formatting strings to be converted into a DataFrame.\n",
    "fh_fit = re.split('\\n', fh_fit)\n",
    "\n",
    "for i in range(len(fh_fit)):        \n",
    "    fh_fit[i] = re.sub('      ', ' ', fh_fit[i])\n",
    "    fh_fit[i] = re.sub('     ', '  ', fh_fit[i])\n",
    "    fh_fit[i] = re.sub('    ', '  ', fh_fit[i])\n",
    "    fh_fit[i] = re.sub('   ','  ', fh_fit[i])\n",
    "    fh_fit[i] = re.sub('  ', ' ', fh_fit[i])\n",
    "    fh_fit[i] = re.sub('dual', 'Residual', fh_fit[i])\n",
    "    fh_fit[i] = re.split(' ', fh_fit[i])\n",
    "\n",
    "## Putting data into a DataFrame: df_fit.\n",
    "df_fit = pd.DataFrame(fh_fit)\n",
    "df_fit = df_fit[3:]\n",
    "str(df_fit[3])\n",
    "\n",
    "## Establishing the column titles using the existing titles printed by Hydrus 1D.\n",
    "for i in range(8):\n",
    "    df_fit[df_fit[i][3]] = df_fit[i]\n",
    "    df_fit = df_fit.drop(columns = [i])\n",
    "\n",
    "## Dropping unneccessary rows and columns, and resetting the index to start from zero.\n",
    "df_fit = df_fit[1:]\n",
    "df_fit = df_fit.reset_index(0)\n",
    "df_fit = df_fit.drop(columns = ['index', 'No'])\n",
    "\n",
    "## Converting all DataFrame info from type string to type float for plotting and potential calculations.\n",
    "for j in range(len(df_fit)):\n",
    "    df_fit['Time'][j] = float(df_fit['Time'][j])           # [sec]       Time\n",
    "    df_fit['Obs'][j] = float(df_fit['Obs'][j])             # [cm^3/cm^2] Volume H2O out of sample/cell cross section area\n",
    "    df_fit['Fitted'][j] = float(df_fit['Fitted'][j])       # [cm^3/cm^2] Volume H2O out of sample/cell cross section area\n",
    "    df_fit['Residual'][j] = float(df_fit['Residual'][j])   # [unitless]  Residual between Obs and Fitted\n",
    "    df_fit['Type'][j] = float(df_fit['Type'][j])           # -           -\n",
    "    df_fit['Position'][j] = float(df_fit['Position'][j])   # -           -\n",
    "\n",
    "#........................................................................................................................\n",
    "    \n",
    "# Retrieving sample specifications from the sample design sheet: sample height (H_sample) [cm],\n",
    "# sample diameter (D_sample) [cm], and porosity (n).\n",
    "\n",
    "## Opening the text file.\n",
    "fh_SD = open(\"Sample_Design.txt\", \"r\")\n",
    "fh_SD = fh_SD.read()\n",
    "\n",
    "## Segragating the text into managable strings.\n",
    "fh_SD = re.sub(' \\t ', '', fh_SD)\n",
    "fh_SD = fh_SD.split('\\n')\n",
    "fh_SD = pd.DataFrame(fh_SD)\n",
    "\n",
    "##  Extracting the values of H_sample [cm], D_sample [cm], and porosity.\n",
    "Height = fh_SD[0][8]; Height = Height.split(' '); H_sample = float(Height[3])            # [cm]\n",
    "Diameter = fh_SD[0][3]; Diameter = Diameter.split(' '); D_sample = float(Diameter[2])    # [cm]\n",
    "Porosity = fh_SD[0][10]; Porosity = Porosity.split(' '); porosity = float(Porosity[3])   # -    \n",
    "\n",
    "## Calculating the cross section area and volume of the test specimine: needed for conversions.\n",
    "A_sample = np.pi * D_sample**2 / 4   # [cm^2] Sample cross section area\n",
    "V_sample = A_sample * H_sample       # [cm^3] Sample volume\n",
    "\n",
    "## Unit convertions: [cm^3/cm^2] Volume H2O out/cell cross section area to [cm^3/cm^3] Volumetric Water Content,\n",
    "## and time [sec] to time [days].\n",
    "df_fit.Obs = (df_fit.Obs * A_sample + porosity*100) / V_sample         # [cm^3/cm^3] Volumetric Water Content of sample\n",
    "df_fit.Fitted = (df_fit.Fitted * A_sample + porosity*100) / V_sample   # [cm^3/cm^3] Volumetric Water Content of sample\n",
    "#df_fit.Obs = abs(df_fit.Obs * A_sample) #+ porosity*100) #/ V_sample         # [gr. H2O] Mass Water out of sample\n",
    "#df_fit.Fitted = abs(df_fit.Fitted * A_sample) #+ porosity*100) #/ V_sample   # [gr. H2O] Mass Water out of sample\n",
    "df_fit.Time = df_fit.Time #/ 86400                                      # [days]      Convert sec. to days\n",
    "\n",
    "#........................................................................................................................\n",
    "\n",
    "# Handeling of SWCC data: matric suction (Pressure, log P) [cm H2O], volumetric water content (WC) [cm^3/cm^3], and\n",
    "# variations of unsaturated hydraulic conductivity (Rel K, log RK, Abs K, log KA) [cm/s] and diffused air (Diffus, log D)\n",
    "\n",
    "## Accessing the SWCC data fromt the main text file.\n",
    "fh_SWCC_soil = fh[11]\n",
    "\n",
    "## Formatting strings to be converted into a DataFrame.\n",
    "fh_SWCC_soil = re.split(\"\\n\", fh_SWCC_soil)\n",
    "\n",
    "for i in range(len(fh_SWCC_soil)):        \n",
    "    fh_SWCC_soil[i] = re.sub('     ', '  ', fh_SWCC_soil[i])\n",
    "    fh_SWCC_soil[i] = re.sub('    ', '  ', fh_SWCC_soil[i])\n",
    "    fh_SWCC_soil[i] = re.sub('   ', '  ', fh_SWCC_soil[i])\n",
    "    fh_SWCC_soil[i] = re.sub('  ', '  ', fh_SWCC_soil[i])\n",
    "    if i == 0:\n",
    "        fh_SWCC_soil[i] = re.split('  ', fh_SWCC_soil[i])\n",
    "    else:\n",
    "        fh_SWCC_soil[i] = re.sub('  ', ' ', fh_SWCC_soil[i])\n",
    "        fh_SWCC_soil[i] = re.split(' ', fh_SWCC_soil[i])\n",
    "\n",
    "## Putting data into a DataFrame: df_SWCC_soil.\n",
    "df_SWCC_soil = pd.DataFrame(fh_SWCC_soil)\n",
    "\n",
    "## Establishing the column titles using the existing titles printed by Hydrus 1D.\n",
    "for i in range(9):\n",
    "    df_SWCC_soil[df_SWCC_soil[i+1][0]] = df_SWCC_soil[i+1][1:len(df_SWCC_soil)]\n",
    "    df_SWCC_soil = df_SWCC_soil.drop(columns = [i+1])\n",
    "\n",
    "## Converting the type 'NoneType' in these rows to type string.\n",
    "df_SWCC_soil['Log KA'][1] = str(df_SWCC_soil['Log KA'][1])\n",
    "df_SWCC_soil['Diffus'][1] = str(df_SWCC_soil['Diffus'][1])\n",
    "df_SWCC_soil['Log D'][1] = str(df_SWCC_soil['Log D'][1])\n",
    "\n",
    "## Replacing missing data with numpy NaN (including the 'NoneType' data which was converted to type 'string').\n",
    "idx_missing = df_SWCC_soil.isin(['', 'None'])\n",
    "df_SWCC_soil[idx_missing] = np.nan\n",
    "\n",
    "## Dropping unneccessary rows and columns, and resetting the index to start from zero.\n",
    "df_SWCC_soil = df_SWCC_soil[1:len(df_SWCC_soil)]\n",
    "df_SWCC_soil = df_SWCC_soil.reset_index(0)\n",
    "df_SWCC_soil = df_SWCC_soil.drop(columns = ['index'])\n",
    "\n",
    "## Converting all DataFrame info from type string to type float for plotting and potential calculations.\n",
    "for j in range(len(df_SWCC_soil)):\n",
    "    df_SWCC_soil['Pressure'][j] = float(df_SWCC_soil['Pressure'][j])   # [cm H2O]        Matric Suction\n",
    "    df_SWCC_soil['Log P'][j] = float(df_SWCC_soil['Log P'][j])         # [log cm H20]    -\n",
    "    df_SWCC_soil['WC'][j] = float(df_SWCC_soil['WC'][j])               # [cm^3/cm^3]     Volumetric Water Content\n",
    "    df_SWCC_soil['Rel K'][j] = float(df_SWCC_soil['Rel K'][j])         # [cm/s]          Unsaturated Hydraulic Conductivity (UHC)\n",
    "    df_SWCC_soil['Log RK'][j] = float(df_SWCC_soil['Log RK'][j])       # [log cm/s]      -\n",
    "    df_SWCC_soil['Abs K'][j] = float(df_SWCC_soil['Abs K'][j])         # [abs cm/s]      Absolute Value UHC\n",
    "    df_SWCC_soil['Log KA'][j] = float(df_SWCC_soil['Log KA'][j])       # [log abs cm/s]  -\n",
    "    df_SWCC_soil['Diffus'][j] = float(df_SWCC_soil['Diffus'][j])       # [cm^3/cm^3]     Diffused Air\n",
    "    df_SWCC_soil['Log D'][j] = float(df_SWCC_soil['Log D'][j])         # [log cm^3/cm^3] -\n",
    "    \n",
    "#........................................................................................................................\n",
    "\n",
    "# Read the csv file to check for mistakes.\n",
    "#df2 = pd.read_csv(\"TRIM_input.csv\", sep = \"\\t\")\n",
    "#df2_Mass = df2_Obj_fcn['Mass (g)']\n",
    "#df2_Time = df2_Obj_fcn['Time']\n",
    "#df2_Date = df2_Obj_fcn['Date']\n",
    "\n",
    "## Converting time from [[YYYY/MM/DD], [HH:MM AM/PM]] to [sec] for calculations and plotting.\n",
    "#df2['Datetime'] = pd.to_datetime(df2.Date + \" \" + df2.Time)                  # from [[MM/DD/YYYY], [HH:MM, AM/PM]] to [YYYY/MM/DD, HH:MM:SS].\n",
    "#df2['Time_diff']= df2.Datetime - df2.Datetime[0]                         # from [YYYY/MM/DD, HH:MM:SS] to [days, HH:MM:SS].\n",
    "#df2['Delta_sec']= df2.Time_diff.dt.days*86400 + df2.Time_diff.dt.seconds   # from [days, HH:MM:SS] to [sec].\n",
    "\n",
    "#........................................................................................................................\n",
    "                 \n",
    "# Plotting the objective function (observed and fitted curves), and the soil water characteristic curve (SWCC) with\n",
    "# the hydraulic conductivity function (HCF).\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "## Plotting of the objective function: observed volumeteric water content (Obs) [cm^3/cm^3], and \n",
    "## fitted volumetric water content (Fitted) [cm^3/cm^3] vs. Time [days] with statistics: R^2, RMSE, and SSQ.\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(df_fit.Time, df_fit.Obs, ':r', label = \"$Observed$\", alpha = 0.9)\n",
    "plt.plot(df_fit.Time, df_fit.Fitted, ':k', label = \"$Fitted$\", alpha = 0.6)\n",
    "#plt.plot(df2['Delta_sec'], df2['Mass (g)'], 'g', label = \"$Sampled$\", alpha = 0.4)\n",
    "plt.title(\"$Objective\\ Function$\", fontsize = 16)\n",
    "plt.ylabel(\"$Volumetric\\ Water\\ Conten\\ (cm^3/cm^3)$\", fontsize = 14)\n",
    "plt.xlabel(\"$Time\\ (days)$\", fontsize = 14)\n",
    "plt.legend(loc = 0) # Posistions legend in the best location.\n",
    "#plt.xlim(0)\n",
    "plt.ylim(0,.40)\n",
    "plt.text(0.005, 0.01, R_2_value , fontsize = 8, horizontalalignment ='left', verticalalignment ='bottom')\n",
    "plt.text(0.005, 0.025, RMSE_value , fontsize = 8, horizontalalignment ='left', verticalalignment ='bottom')\n",
    "plt.text(0.005, 0.036, SSQ , fontsize = 8, horizontalalignment ='left', verticalalignment ='bottom')\n",
    "\n",
    "## Plotting of the SWCC: Matric Suction Head [cm/H2O] vs. Volumetric Water Content [cm^3/cm^3],\n",
    "## with optimized van Genuchten fitting parameters: residual volumetric water content (theta_r) [cm^3/cm^3],\n",
    "## inverse of air entry (alpha) [1/cm], pore size distribution parameter (n), and permeability (K_s) [cm/s].\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(df_SWCC_soil['WC'], df_SWCC_soil['Pressure'], \"g\", label = \"SWCC\", alpha = 0.8)\n",
    "plt.title(\"$Unsaturated\\ Characteristics$\", fontsize = 16)\n",
    "plt.ylabel(\"$Matric\\ Suction\\ (cm\\ H_2O)$\", color = 'green', fontsize = 14)\n",
    "plt.xlabel(\"$Volumetric\\ Water\\ Content\\ (cm^3/cm^3)$\", fontsize = 14)\n",
    "plt.legend(loc = 9) # Posistions legend in the upper center.\n",
    "plt.yscale('log')   # Y-axis in log scale.\n",
    "plt.xlim(0,.40)\n",
    "plt.ylim(1,10**7)\n",
    "plt.grid()\n",
    "plt.text(0.005, 10**6, WCR , fontsize = 8, horizontalalignment ='left', verticalalignment ='bottom')\n",
    "plt.text(0.005, 1.8*10**6, ALPHA , fontsize = 8, horizontalalignment ='left', verticalalignment ='bottom')\n",
    "plt.text(0.005, 3*10**6, N , fontsize = 8, horizontalalignment ='left', verticalalignment ='bottom')\n",
    "plt.text(0.005, 4.5*10**6, K_SAT , fontsize = 8, horizontalalignment ='left', verticalalignment ='bottom')\n",
    "\n",
    "## Plotting of the HCF: Unsaturated Hydraulic Conductivity [cm/s] vs. Volumetric Water Content [cm^3/cm^3].\n",
    "## Plotting on the same graph as the SWCC.\n",
    "plt.twinx()\n",
    "plt.plot(df_SWCC_soil['WC'], df_SWCC_soil['Abs K'], \":b\", label = \"HCF\", alpha = 0.8)\n",
    "plt.ylabel(\"$K_s\\ (cm/s)$\", color = 'blue', fontsize = 14)\n",
    "plt.legend(loc = 1) # Posistions legend in the upper right corner.\n",
    "plt.yscale('log')   # Y-axis in log scale.\n",
    "plt.ylim(10**-17,10**-2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## Plot caption...\n",
    "print(\"\\nFigures 2 & 3: Objective Function and Unsaturated Characteristics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df2.Delta_sec,df2['Mass (g)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.94772284419682"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.32487152805936"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
